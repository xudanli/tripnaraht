#!/usr/bin/env python3
"""
åŸå¸‚æ•°æ®å¯¼å…¥è„šæœ¬ï¼ˆç®€åŒ–ç‰ˆ - ä»…ä½¿ç”¨ Python æ ‡å‡†åº“ï¼‰
ç›´æ¥è¯»å– CSV æ–‡ä»¶å¹¶å¯¼å…¥åˆ° PostgreSQL æ•°æ®åº“
"""

import sys
import csv
import json
import psycopg2
from pathlib import Path
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ•°æ®åº“è¿æ¥é…ç½®
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 5432)),
    'database': os.getenv('DB_NAME', 'postgres'),
    'user': os.getenv('DB_USER', 'postgres'),
    'password': os.getenv('DB_PASSWORD', ''),
}

# å¦‚æœ DATABASE_URL å­˜åœ¨ï¼Œè§£æå®ƒ
DATABASE_URL = os.getenv('DATABASE_URL')
if DATABASE_URL:
    # è§£æ postgresql://user:password@host:port/database
    import re
    match = re.match(r'postgresql://([^:]+):([^@]+)@([^:]+):(\d+)/([^?]+)', DATABASE_URL)
    if match:
        DB_CONFIG['user'] = match.group(1)
        DB_CONFIG['password'] = match.group(2)
        DB_CONFIG['host'] = match.group(3)
        DB_CONFIG['port'] = int(match.group(4))
        DB_CONFIG['database'] = match.group(5)


def extract_field_value(row: dict, field_names: list) -> str:
    """ä»è¡Œæ•°æ®ä¸­æå–å­—æ®µå€¼ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰"""
    for field in field_names:
        if field in row and row[field] and row[field].strip():
            return row[field].strip()
    return None


def convert_row_to_city_data(row: dict) -> dict:
    """å°† CSV è¡Œè½¬æ¢ä¸º City è¡¨æ•°æ®æ ¼å¼"""
    # å¿…éœ€å­—æ®µ
    name = extract_field_value(row, ['NAME', 'name', 'city', 'cityName'])
    country_code = extract_field_value(row, ['ISO_A2', 'countryCode', 'country_code', 'iso_code'])
    
    if not name or not country_code:
        return None
    
    # éªŒè¯å›½å®¶ä»£ç æ ¼å¼
    country_code = country_code.upper().strip()
    if len(country_code) != 2 or not country_code.isalpha():
        return None
    
    city_data = {
        'name': name,
        'countryCode': country_code,
    }
    
    # å¯é€‰å­—æ®µ
    name_cn = extract_field_value(row, ['NAME_ZH', 'NAME_ZHT', 'nameCN', 'name_zh'])
    if name_cn:
        city_data['nameCN'] = name_cn
    
    name_en = extract_field_value(row, ['NAME_EN', 'nameEN', 'name_en'])
    if name_en:
        city_data['nameEN'] = name_en
    
    # åæ ‡
    lat_str = extract_field_value(row, ['çº¬åº¦', 'LAT', 'latitude', 'lat', 'y'])
    lng_str = extract_field_value(row, ['ç»åº¦', 'LNG', 'LON', 'longitude', 'lng', 'lon', 'x'])
    
    if lat_str and lng_str:
        try:
            city_data['latitude'] = float(lat_str)
            city_data['longitude'] = float(lng_str)
        except (ValueError, TypeError):
            pass
    
    # æ—¶åŒº
    timezone = extract_field_value(row, ['TIMEZONE', 'TIMEZO', 'timezone', 'timeZone'])
    if timezone and len(timezone) > 3:
        city_data['timezone'] = timezone
    
    # Metadataï¼ˆæ‰©å±•ä¿¡æ¯ï¼‰
    metadata = {}
    
    # è¡Œæ”¿åŒºåˆ’
    adm0 = extract_field_value(row, ['ADM0NAME', 'country', 'å›½å®¶'])
    if adm0:
        metadata['adminLevel0'] = adm0
    
    adm1 = extract_field_value(row, ['ADM1NAME', 'province', 'state', 'çœ', 'å·'])
    if adm1:
        metadata['adminLevel1'] = adm1
    
    # å¤–éƒ¨ID
    wikidata_id = extract_field_value(row, ['WIKIDATAID', 'WIKID/A', 'wikidataId'])
    if wikidata_id:
        metadata['wikidataId'] = wikidata_id
    
    geonames_id = extract_field_value(row, ['GEONAMESID', 'geonamesId'])
    if geonames_id:
        try:
            metadata['geonamesId'] = int(geonames_id)
        except (ValueError, TypeError):
            metadata['geonamesId'] = geonames_id
    
    wof_id = extract_field_value(row, ['WOF_ID', 'wofId'])
    if wof_id:
        try:
            metadata['wofId'] = int(wof_id)
        except (ValueError, TypeError):
            metadata['wofId'] = wof_id
    
    # å…¶ä»–è¯­è¨€åç§°
    lang_fields = {
        'NAME_DE': 'nameDE',
        'NAME_ES': 'nameES',
        'NAME_FR': 'nameFR',
        'NAME_JA': 'nameJA',
        'NAME_KO': 'nameKO',
    }
    
    for source_field, target_key in lang_fields.items():
        value = extract_field_value(row, [source_field])
        if value:
            metadata[target_key] = value
    
    # è¦ç´ åˆ†ç±»
    feature_class = extract_field_value(row, ['FEATURECLA', 'featureClass'])
    if feature_class:
        metadata['featureClass'] = feature_class
    
    if metadata:
        city_data['metadata'] = json.dumps(metadata, ensure_ascii=False)
    
    return city_data


def import_cities_to_db(cities_data: list, batch_size: int = 500):
    """å¯¼å…¥åŸå¸‚æ•°æ®åˆ°æ•°æ®åº“"""
    print(f"ğŸ”Œ è¿æ¥æ•°æ®åº“: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}")
    
    try:
        conn = psycopg2.connect(**DB_CONFIG)
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        print(f"   è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ DATABASE_URL æˆ–æ•°æ®åº“é…ç½®")
        sys.exit(1)
    
    cur = conn.cursor()
    
    try:
        success_count = 0
        skipped_count = 0
        error_count = 0
        
        print(f"\nğŸ“Š å¼€å§‹å¯¼å…¥ {len(cities_data)} æ¡æ•°æ®...\n")
        
        for i, city in enumerate(cities_data, 1):
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                cur.execute("""
                    SELECT id FROM "City" 
                    WHERE name = %s AND "countryCode" = %s
                """, (city['name'], city['countryCode']))
                
                existing = cur.fetchone()
                if existing:
                    skipped_count += 1
                    if i % 100 == 0:
                        progress = (i / len(cities_data) * 100)
                        print(f"è¿›åº¦: {i}/{len(cities_data)} ({progress:.1f}%) - å·²å­˜åœ¨: {skipped_count}, æˆåŠŸ: {success_count}, é”™è¯¯: {error_count}")
                    continue
                
                # æ„å»º SQL
                fields = ['name', '"countryCode"']
                values = [city['name'], city['countryCode']]
                placeholders = ['%s', '%s']
                
                if 'nameCN' in city:
                    fields.append('"nameCN"')
                    values.append(city['nameCN'])
                    placeholders.append('%s')
                
                if 'nameEN' in city:
                    fields.append('"nameEN"')
                    values.append(city['nameEN'])
                    placeholders.append('%s')
                
                if 'timezone' in city:
                    fields.append('timezone')
                    values.append(city['timezone'])
                    placeholders.append('%s')
                
                if 'metadata' in city:
                    fields.append('metadata')
                    values.append(city['metadata'])
                    placeholders.append('%s::jsonb')
                
                # å¦‚æœæœ‰åæ ‡ï¼Œä½¿ç”¨ PostGIS
                if 'latitude' in city and 'longitude' in city:
                    fields.append('location')
                    placeholders.append('ST_SetSRID(ST_MakePoint(%s, %s), 4326)')
                    sql = f"""
                        INSERT INTO "City" ({', '.join(fields)})
                        VALUES ({', '.join(placeholders)})
                        RETURNING id
                    """
                    final_values = values.copy()
                    final_values.extend([city['longitude'], city['latitude']])
                    cur.execute(sql, final_values)
                else:
                    sql = f"""
                        INSERT INTO "City" ({', '.join(fields)})
                        VALUES ({', '.join(placeholders)})
                        RETURNING id
                    """
                    cur.execute(sql, values)
                
                city_id = cur.fetchone()[0]
                success_count += 1
                
                # æ¯ batch_size æ¡æäº¤ä¸€æ¬¡ï¼Œå¹¶æ˜¾ç¤ºè¿›åº¦
                if i % batch_size == 0:
                    conn.commit()
                    progress = (i / len(cities_data) * 100)
                    print(f"è¿›åº¦: {i}/{len(cities_data)} ({progress:.1f}%) - å·²å­˜åœ¨: {skipped_count}, æˆåŠŸ: {success_count}, é”™è¯¯: {error_count}")
                elif i % 100 == 0:
                    progress = (i / len(cities_data) * 100)
                    print(f"è¿›åº¦: {i}/{len(cities_data)} ({progress:.1f}%) - å·²å­˜åœ¨: {skipped_count}, æˆåŠŸ: {success_count}, é”™è¯¯: {error_count}")
                
            except Exception as e:
                error_count += 1
                print(f"âŒ å¯¼å…¥å¤±è´¥: {city.get('name', 'Unknown')} - {str(e)}")
                conn.rollback()
        
        # æœ€ç»ˆæäº¤
        conn.commit()
        
        print(f"\n{'='*50}")
        print(f"ğŸ“Š å¯¼å…¥å®Œæˆ:")
        print(f"  âœ… æˆåŠŸåˆ›å»º: {success_count}")
        print(f"  â­ï¸  å·²å­˜åœ¨ï¼ˆè·³è¿‡ï¼‰: {skipped_count}")
        print(f"  âŒ å¤±è´¥: {error_count}")
        print(f"{'='*50}\n")
        
    finally:
        cur.close()
        conn.close()


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python import_cities_simple.py <CSVæ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    
    file_path = sys.argv[1]
    file_path = Path(file_path)
    
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        sys.exit(1)
    
    try:
        # è¯»å– CSV æ–‡ä»¶
        print(f"ğŸ“‚ è¯»å–æ–‡ä»¶: {file_path}\n")
        
        cities_data = []
        skipped = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            total_rows = 0
            
            for idx, row in enumerate(reader, 1):
                total_rows = idx
                city_data = convert_row_to_city_data(row)
                if city_data:
                    cities_data.append(city_data)
                else:
                    skipped.append(idx)
        
        print(f"âœ… è¯»å–å®Œæˆ: {total_rows} è¡Œ")
        print(f"âœ… è½¬æ¢å®Œæˆ: {len(cities_data)} æ¡æœ‰æ•ˆæ•°æ®")
        if skipped:
            print(f"â­ï¸  è·³è¿‡: {len(skipped)} æ¡ï¼ˆç¼ºå°‘å¿…éœ€å­—æ®µï¼‰")
        
        if not cities_data:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯å¯¼å…¥")
            sys.exit(1)
        
        # å¯¼å…¥æ•°æ®åº“
        import_cities_to_db(cities_data)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()

